# WEEK 3: Cache Integration & Multi-Org Data Isolation

## ğŸ¯ Objetivo
Implementar el sistema de caching para que:
- âœ… Cuando admin sube CSVs â†’ se procesan â†’ se cachean en Supabase
- âœ… Siguientes usuarios leen desde cache (instant load)
- âœ… Datos estÃ¡n aislados por organizaciÃ³n
- âœ… Si data_loaded=TRUE â†’ no mostrar upload form (solo admins pueden refrescar)

## ğŸ“‹ Lo que se implementÃ³

### 1. **MÃ³dulo cache_service** (`src/services/cache_service.py`)

Dos funciones principales:

#### `check_and_load_org_cache(db, org_id)`
```python
has_cache, data_dict = check_and_load_org_cache(db, org_id)
# Returns:
# - has_cache: bool (Â¿hay cache?)
# - data_dict: {
#     demand_monthly: DataFrame,
#     stock_monthly: DataFrame,
#     movements: DataFrame,
#     csv_files_count: int,
#     updated_at: timestamp
#   }
```

**QuÃ© hace:**
1. Verifica si `org.data_loaded = TRUE`
2. Si sÃ­, carga JSON de `org_cache`
3. Deserializa DataFrames (json â†’ pandas)
4. Retorna datos listos para usar

#### `save_org_cache(db, org_id, movements, demand_monthly, stock_monthly, processed_by, csv_files_count)`
**QuÃ© hace:**
1. Serializa DataFrames a JSON
2. Guarda en `org_cache` (INSERT o UPDATE)
3. Marca `org.data_loaded = TRUE`

### 2. **Dashboard Updates** (`src/ui/dashboard.py`)

#### Nuevo flujo de data loading:
```
Login completado
    â†“
Check: Â¿hay cache para esta org?
    â†“
SI: âœ… Cargar desde cache (instant)
    â”œâ”€ Mostrar: "âœ… Datos Cacheados"
    â”œâ”€ Mostrar: Ãºltima actualizaciÃ³n
    â””â”€ Continuar al anÃ¡lisis
    â†“
NO: â“ Â¿Es admin?
    â”œâ”€ SI: Mostrar upload form
    â”‚   â”œâ”€ Upload CSVs a S3
    â”‚   â”œâ”€ Procesar con DataPipeline
    â”‚   â”œâ”€ Guardar en org_cache
    â”‚   â””â”€ Continuar al anÃ¡lisis
    â”‚
    â””â”€ NO: Mostrar "â³ Esperando..."
        â””â”€ Return (sin datos)
```

#### Cambios especÃ­ficos:
1. **Import nuevo:**
   ```python
   from src.services.cache_service import check_and_load_org_cache, save_org_cache
   ```

2. **Check de cache (despuÃ©s del login):**
   ```python
   has_cache, cached_data = check_and_load_org_cache(db, org_id)
   
   if has_cache and cached_data:
       # Cargar desde cache
       res_movements = cached_data.get("movements")
       res_demand = cached_data.get("demand_monthly")
       res_stock = cached_data.get("stock_monthly")
   ```

3. **Condicional por rol:**
   - Si admin: mostrar upload form
   - Si viewer: mostrar "esperando..."

4. **Guardar en cache despuÃ©s de procesar:**
   ```python
   cache_saved = save_org_cache(
       db=db, org_id=org_id,
       movements=res.movements,
       demand_monthly=res.demand_monthly,
       stock_monthly=res.stock_monthly,
       processed_by=user_id,
       csv_files_count=len(saved_files)
   )
   ```

5. **Referenciar data cacheada en tabs:**
   - Antes: `res.demand_monthly`, `res.movements`, `res.stock_monthly`
   - Ahora: `res_demand`, `res_movements`, `res_stock`

## ğŸ§ª Tests Pasados

```
âœ… syntax validation - dashboard.py OK
âœ… cache_service imports OK
âœ… All res.* references fixed
```

## ğŸ“Š Arquitectura de Datos (WEEK 3)

```
org_cache table (Supabase):
  organization_id (PK)
  demand_monthly (JSONB)  â† Serialized DataFrame
  stock_monthly (JSONB)   â† Serialized DataFrame
  movements (JSONB)       â† Serialized DataFrame
  updated_at (timestamp)
  processed_by (user_id)
  csv_files_count (int)

Flujo:
[Admin upload] â†’ [Pipeline.run()] â†’ [serialize] â†’ [save org_cache] â†’ [data_loaded=TRUE]
                                                        â†“
                                    [Next user login] â†’ [check_and_load] â†’ [instant load]
```

## ğŸ® CÃ³mo Probar WEEK 3

### Prerequisito: Tener WEEK 1+2 completado
âœ… SQL de WEEK 1 ejecutado
âœ… Org y usuarios creados en WEEK 2

### Test Setup

En Supabase SQL Editor:
```sql
-- Crear org de prueba
INSERT INTO organizations (nombre, description) 
VALUES ('Test Cache Org', 'Testing cache system');

-- Copiar el ID (ej: 550e8400-...)
-- Actualizar usuario admin para esta org
UPDATE users 
SET organization_id = '550e8400-...',
    is_admin = TRUE
WHERE email = 'admin@test.com';
```

### Paso 1: Admin sube datos
1. Login como admin@test.com
2. Ir a tab "ğŸ“¤ Subir Datos"
3. Subir CSVs (usa el sample_data.csv si tienes)
4. Ver en sidebar: "ğŸ’¾ Guardando datos en cache..."
5. Ver: "âœ… Datos guardados en cache"
6. Los datos deberÃ­an aparecer en las tabs de anÃ¡lisis

### Paso 2: Verificar que se guardÃ³ en cache
En Supabase Console â†’ Table Editor â†’ org_cache:
- âœ… Debe haber un row con tu org_id
- âœ… demand_monthly y stock_monthly deben tener JSON
- âœ… updated_at debe ser reciente

### Paso 3: Login como nuevo usuario (viewer)
1. Logout
2. Request que admin cree otro usuario: viewer2@test.com (sin admin role)
3. Login como viewer2@test.com
4. **IMPORTANTE:** Sidebar debe mostrar: "âœ… Datos Cacheados"
5. **NO deberÃ­a haber upload form**
6. Los datos en las tabs deben ser **idÃ©nticos** a los que vio el admin

### Paso 4: Verificar aislamiento de datos (BONUS)
Si tienes 2 orgs:
1. Org A (admin1): sube datos A
2. Org B (admin2): sube datos B
3. user_a login (en org A): ve datos A
4. user_b login (en org B): ve datos B
5. **Verificar:** Datos son totalmente aislados

## ğŸ“ PrÃ³ximos Pasos (WEEK 4)

Una vez WEEK 3 funcione:
- [ ] Deploy a Streamlit Cloud
- [ ] Configurar environment variables en cloud
- [ ] Test multi-org en producciÃ³n
- [ ] Performance testing

## ğŸ” Debugging

### Si sidebar muestra "âš ï¸ Sin Datos Cacheados" pero ya subiste:
1. Verificar org_cache table en Supabase:
   ```sql
   SELECT organization_id, csv_files_count, updated_at FROM org_cache;
   ```
2. Verificar que org.data_loaded = TRUE:
   ```sql
   SELECT id, nombre, data_loaded FROM organizations;
   ```

### Si viewer ve upload form (no deberÃ­a):
- Verificar is_admin de usuario:
  ```sql
  SELECT email, is_admin, organization_id FROM users;
  ```

### Si datos son diferentes entre admin y viewer:
- Puede ser que cache no se cargÃ³ bien
- Verificar que deserialize estÃ¡ funcionando
- Ver logs de check_and_load_org_cache()

## âœ… Checklist WEEK 3

- [ ] cache_service.py creado y funciona
- [ ] Dashboard importa cache_service correctamente
- [ ] Admin sube data â†’ se cachea â†’ se guarda en org_cache
- [ ] Sidebar muestra "Datos Cacheados" despuÃ©s de admin upload
- [ ] Viewer ve datos desde cache (sin upload form)
- [ ] Datos correctamente aislados por org
- [ ] All res.* â†’ res_* references fixed
- [ ] Syntax validation passes

## ğŸ“š Archivos Principales

| Archivo | Purpose | Status |
|---------|---------|--------|
| `src/services/cache_service.py` | Cache load/save | âœ… New |
| `src/ui/dashboard.py` | Main dashboard (updated) | âœ… Modified |
| `src/utils/cache_helpers.py` | JSON serialization | âœ… Ready |
| `src/db/supabase.py` | Org & cache DB ops | âœ… Ready |

---

## ğŸ”— Referencia

**Volver a:**
- [WEEK1_SETUP.md](WEEK1_SETUP.md) - Database schema
- [WEEK2_SETUP.md](WEEK2_SETUP.md) - Admin panel

**PrÃ³ximo:**
- [WEEK4_DEPLOYMENT.md](WEEK4_DEPLOYMENT.md) - Cloud deployment (TBD)
